{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.5914887264547102\n",
      "F1 Score: 0.5708057938405288\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic observed data\n",
    "num_samples = 100000\n",
    "\n",
    "# Environmental variables (affect occupancy)\n",
    "env_variables = np.random.rand(num_samples, 3)  # env_var1, env_var2, env_var3\n",
    "env_df = pd.DataFrame(env_variables, columns=['env_var1', 'env_var2', 'env_var3'])\n",
    "\n",
    "# Detection variables (affect detection probability)\n",
    "detect_variables = np.random.rand(num_samples, 2)  # detect_var1, detect_var2\n",
    "detect_df = pd.DataFrame(detect_variables, columns=['detect_var1', 'detect_var2'])\n",
    "\n",
    "# Fixed occupancy probability based on environmental variables\n",
    "occupancy_prob = np.where(env_df['env_var1'] > 0.5, 0.8, 0.3)\n",
    "occupancy_prob += np.where(env_df['env_var2'] > 0.6, 0.1, 0)\n",
    "occupancy_prob = np.clip(occupancy_prob, 0, 1)\n",
    "\n",
    "# Fixed detection probability based on detection variables\n",
    "detection_prob = np.where(detect_df['detect_var1'] > 0.5, 0.7, 0.4)\n",
    "detection_prob += np.where(detect_df['detect_var2'] > 0.3, 0.2, 0)\n",
    "detection_prob = np.clip(detection_prob, 0, 1)\n",
    "\n",
    "# Combined probability of detection: occupancy_prob * detection_prob\n",
    "# (optional: can still be occupancy_prob + detection_prob if needed)\n",
    "combined_prob = occupancy_prob * detection_prob\n",
    "\n",
    "# Observed detection outcomes (we only observe this)\n",
    "detection = np.random.binomial(1, combined_prob)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "data = pd.concat([env_df, detect_df], axis=1)\n",
    "data['detection'] = detection\n",
    "data['true_occupancy_prob'] = occupancy_prob\n",
    "data['true_detection_prob'] = detection_prob\n",
    "\n",
    "# Calculate ROC AUC score for evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "auc_score = roc_auc_score(\n",
    "    np.random.binomial(1, occupancy_prob), detection\n",
    ")\n",
    "print(\"ROC AUC Score:\", auc_score)\n",
    "print(\"F1 Score:\", f1_score(np.random.binomial(1, occupancy_prob), detection))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "# Create synthetic observed data\n",
    "num_samples = 100000\n",
    "\n",
    "# Environmental variables (affect occupancy)\n",
    "env_variables = np.random.rand(num_samples, 3)  # env_var1, env_var2, env_var3\n",
    "env_df = pd.DataFrame(env_variables, columns=['env_var1', 'env_var2', 'env_var3'])\n",
    "\n",
    "# Detection variables (affect detection probability)\n",
    "detect_variables = np.random.normal(loc=0.7, scale=0.2, size=(num_samples, 2))  # detect_var1, detect_var2\n",
    "detect_df = pd.DataFrame(detect_variables, columns=['detect_var1', 'detect_var2'])\n",
    "\n",
    "# Occupancy probability based on environmental variables\n",
    "occupancy_prob = (\n",
    "    0.6 * env_df['env_var1'] +\n",
    "    0.4 * env_df['env_var2']\n",
    ")\n",
    "\n",
    "occupancy_prob = np.array(occupancy_prob).clip(0, 1)\n",
    "occupancy_prob = expit(20 * (occupancy_prob - 0.5))\n",
    "\n",
    "# Detection probability based on detection variables\n",
    "detection_prob = (\n",
    "    0.7 * detect_df['detect_var1'] +\n",
    "    0.3 * detect_df['detect_var2']\n",
    ")\n",
    "detection_prob = detection_prob.clip(0, 1)\n",
    "\n",
    "# Observed detection outcomes (we only observe this)\n",
    "detection = np.random.binomial(1, np.random.binomial(1, occupancy_prob) * detection_prob)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "data = pd.concat([env_df, detect_df], axis=1)\n",
    "data['detection'] = detection\n",
    "data['true_occupancy_prob'] = occupancy_prob\n",
    "data['true_detection_prob'] = detection_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('detection', axis=1)\n",
    "y = data['detection']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_detection_var_df = X_train[['detect_var1', 'detect_var2']]\n",
    "X_train_occupancy_var_df = X_train[['env_var1', 'env_var2', 'env_var3']]\n",
    "X_test_detection_var_df = X_test[['detect_var1', 'detect_var2']]\n",
    "X_test_occupancy_var_df = X_test[['env_var1', 'env_var2', 'env_var3']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = pd.concat([X_train_detection_var_df.reset_index(drop=True), X_train_occupancy_var_df.reset_index(drop=True)], axis=1)\n",
    "X_test_combined = pd.concat([X_test_detection_var_df.reset_index(drop=True), X_test_occupancy_var_df.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_f1    train_loss    train_roc_auc    valid_acc    valid_f1    valid_loss    valid_precision    valid_recall    valid_roc_auc     dur\n",
      "-------  ----------  ------------  ---------------  -----------  ----------  ------------  -----------------  --------------  ---------------  ------\n",
      "      1      \u001b[36m0.7278\u001b[0m        \u001b[32m0.5009\u001b[0m           \u001b[35m0.8283\u001b[0m       \u001b[31m0.7966\u001b[0m      \u001b[94m0.8127\u001b[0m        \u001b[36m0.4411\u001b[0m             \u001b[32m0.7530\u001b[0m          \u001b[35m0.8826\u001b[0m           \u001b[31m0.8621\u001b[0m  0.6091\n",
      "      2      \u001b[36m0.8161\u001b[0m        \u001b[32m0.4340\u001b[0m           \u001b[35m0.8715\u001b[0m       \u001b[31m0.7966\u001b[0m      \u001b[94m0.8151\u001b[0m        \u001b[36m0.4314\u001b[0m             0.7474          \u001b[35m0.8962\u001b[0m           \u001b[31m0.8734\u001b[0m  0.6071\n",
      "      3      \u001b[36m0.8176\u001b[0m        \u001b[32m0.4262\u001b[0m           \u001b[35m0.8772\u001b[0m       \u001b[31m0.7976\u001b[0m      0.8148        \u001b[36m0.4263\u001b[0m             0.7510          0.8904           \u001b[31m0.8755\u001b[0m  0.6044\n",
      "      4      \u001b[36m0.8181\u001b[0m        \u001b[32m0.4228\u001b[0m           \u001b[35m0.8784\u001b[0m       0.7962      \u001b[94m0.8158\u001b[0m        \u001b[36m0.4258\u001b[0m             0.7443          \u001b[35m0.9023\u001b[0m           \u001b[31m0.8761\u001b[0m  0.6365\n",
      "      5      0.8173        \u001b[32m0.4220\u001b[0m           \u001b[35m0.8788\u001b[0m       \u001b[31m0.7991\u001b[0m      0.8142        \u001b[36m0.4248\u001b[0m             \u001b[32m0.7573\u001b[0m          0.8804           0.8761  0.6408\n",
      "      6      0.8164        \u001b[32m0.4218\u001b[0m           \u001b[35m0.8788\u001b[0m       0.7991      0.8140        \u001b[36m0.4239\u001b[0m             \u001b[32m0.7579\u001b[0m          0.8789           \u001b[31m0.8763\u001b[0m  0.6062\n",
      "      7      0.8173        \u001b[32m0.4215\u001b[0m           \u001b[35m0.8790\u001b[0m       0.7969      0.8056        0.4286             \u001b[32m0.7726\u001b[0m          0.8416           0.8760  0.6429\n",
      "      8      0.8180        \u001b[32m0.4213\u001b[0m           \u001b[35m0.8791\u001b[0m       0.7991      0.8139        \u001b[36m0.4238\u001b[0m             0.7580          0.8787           \u001b[31m0.8763\u001b[0m  0.6475\n",
      "      9      0.8167        \u001b[32m0.4213\u001b[0m           0.8791       0.7974      0.8145        0.4251             0.7510          0.8898           0.8759  0.6050\n",
      "     10      0.8172        0.4215           0.8789       \u001b[31m0.7998\u001b[0m      0.8126        0.4242             0.7636          0.8684           \u001b[31m0.8764\u001b[0m  0.6009\n",
      "     11      0.8170        0.4214           0.8790       0.7987      0.8141        0.4244             0.7564          0.8813           0.8759  0.6081\n",
      "     12      0.8172        0.4216           0.8789       0.7996      0.8132        0.4239             0.7614          0.8727           0.8763  0.5993\n",
      "     13      0.8170        0.4213           0.8790       \u001b[31m0.7999\u001b[0m      0.8132        0.4240             0.7625          0.8710           0.8764  0.6023\n",
      "     14      0.8168        0.4213           0.8790       0.7988      0.8137        0.4238             0.7575          0.8789           \u001b[31m0.8764\u001b[0m  0.5990\n",
      "     15      0.8169        0.4214           0.8790       0.7982      0.8135        \u001b[36m0.4236\u001b[0m             0.7562          0.8803           0.8762  0.6076\n",
      "     16      0.8172        0.4213           0.8789       \u001b[31m0.8003\u001b[0m      0.8134        0.4244             0.7633          0.8705           0.8763  0.6047\n",
      "     17      0.8170        \u001b[32m0.4212\u001b[0m           \u001b[35m0.8791\u001b[0m       0.7999      0.8134        0.4237             0.7620          0.8723           0.8763  0.6253\n",
      "     18      0.8178        \u001b[32m0.4210\u001b[0m           \u001b[35m0.8792\u001b[0m       0.7990      0.8114        0.4241             0.7641          0.8650           0.8762  0.6314\n",
      "     19      0.8174        0.4213           0.8790       0.7974      0.8147        0.4244             0.7507          0.8905           0.8762  0.6263\n",
      "Stopping since valid_roc_auc has not improved in the last 10 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<occupancy_model_nn.occupancy_ml_trainer at 0x168f878d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from occupancy_model_nn import occupancy_ml_trainer\n",
    "model = occupancy_ml_trainer(validation=True, no_mini_batch=False, batch_size=128, tolerance_epoch=10)\n",
    "model.fit(X_train_combined, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8789541561874539\n",
      "0.7351394924996495\n"
     ]
    }
   ],
   "source": [
    "probs = model.predict_proba(X_train_combined)[:,1]\n",
    "print(roc_auc_score(y_train.values.astype('float32'), probs))\n",
    "print(f1_score(y_train.values.astype('float32'), np.where(probs>0.5, 1, 0)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
